{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "505afa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks.python.vision import GestureRecognizer, GestureRecognizerOptions, RunningMode\n",
    "from mediapipe.tasks.python.core.base_options import BaseOptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99e920e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"gesture_recognizer.task\"\n",
    "assert os.path.exists(model_path), f\"Modèle introuvable: {model_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecf49ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760607063.695996 2346892 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M2\n",
      "W0000 00:00:1760607063.711583 2346892 gesture_recognizer_graph.cc:129] Hand Gesture Recognizer contains CPU only ops. Sets HandGestureRecognizerGraph acceleration to Xnnpack.\n",
      "I0000 00:00:1760607063.722339 2346892 hand_gesture_recognizer_graph.cc:250] Custom gesture classifier is not defined.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1760607063.755355 2427035 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760607063.780208 2427035 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760607063.784896 2427033 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760607063.784933 2427033 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "options = GestureRecognizerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=RunningMode.VIDEO,          # IMPORTANT pour recognize_for_video()\n",
    "    num_hands=2,\n",
    "    min_hand_detection_confidence=0.5,\n",
    "    min_hand_presence_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "recognizer = GestureRecognizer.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "553095b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = cv2.CAP_AVFOUNDATION \n",
    "cap = cv2.VideoCapture(0, api)\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(1, api)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Caméra non ouverte (permissions/index).\")\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,  1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))\n",
    "cap.set(cv2.CAP_PROP_CONVERT_RGB, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31d2e788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap.read() a échoué\n"
     ]
    }
   ],
   "source": [
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if not fps or np.isnan(fps) or fps <= 1:\n",
    "    fps = 30.0\n",
    "frame_period_ms = int(1000 / fps)\n",
    "timestamp_ms = 0\n",
    "\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "mp_styles = mp.solutions.drawing_styles\n",
    "\n",
    "while True:\n",
    "    ok, frame_bgr = cap.read()\n",
    "    if not ok or frame_bgr is None:\n",
    "        print(\"cap.read() a échoué\"); break\n",
    "\n",
    "    # MediaPipe Tasks attend un SRGB (RGB)\n",
    "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    mp_image = mp.Image(\n",
    "        image_format=mp.ImageFormat.SRGB,\n",
    "        data=frame_rgb\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb3f14bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes : 988\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/valentindaveau/Downloads/training_set/sequences/4.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    nb_lignes = sum(1 for _ in f)\n",
    "\n",
    "print(\"Nombre de lignes :\", nb_lignes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfmetal310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
