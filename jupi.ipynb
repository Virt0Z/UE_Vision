{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b606f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from keras import layers, preprocessing, callbacks, losses, utils\n",
    "import sys\n",
    "import PyQt5\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QWidget, QVBoxLayout, QHBoxLayout, QGridLayout,QFrame\n",
    "from PyQt5.QtGui import QPixmap, QPainter, QPen, QColor\n",
    "from PyQt5.QtCore import Qt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b0ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('/Users/valentindaveau/reseau/datasets/dataset/base_donnes_iccp_reduite')\n",
    "img_height = 600\n",
    "img_width = 400\n",
    "batch_size = 3      #nombre d'images envoyées à la fois\n",
    "epochs = 3  \n",
    "\n",
    "input_shape=(img_height, img_width,3)\n",
    "num_classes=17\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b077d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1893 files belonging to 52 classes.\n",
      "Using 1515 files for training.\n",
      "Metal device set to: Apple M2\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=42,\n",
    "        image_size=(img_height, img_width),\n",
    "        shuffle=True,                                   #Intialement sans cette ligne : mélange les images pour éviter que le réseau ne catégorise par ordre d'arivée\n",
    "        batch_size=batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9525787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1893 files belonging to 52 classes.\n",
      "Using 378 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_data = utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=42,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af6c6ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted([dir for dir in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, dir))])\n",
    "\n",
    "card_dir = {\n",
    "        '1_carreaux': '/Users/valentindaveau/reseau/datasets/dataset/carreaux/1_carreaux.png',\n",
    "        '2_carreaux': '/Users/valentindaveau/reseau/datasets/dataset/carreaux/2_carreaux.png',\n",
    "        '3_carreaux': '/Users/valentindaveau/reseau/datasets/dataset/carreaux/3_carreaux.png',\n",
    "        '4_carreaux': '/Users/valentindaveau/reseau/datasets/dataset/carreaux/4_carreaux.png',\n",
    "        '5_carreaux': '/Users/valentindaveau/reseau/datasets/dataset/carreaux/5_carreaux.png',\n",
    "        '6_carreaux': '/Users/valentindaveau/reseau/datasets/dataset/carreaux/6_carreaux.png',\n",
    "        '7_carreaux': '/Users/valentindaveau/reseau/datasets/dataset/carreaux/7_carreaux.png',\n",
    "        '8_carreaux': '/Users/valentindaveau/reseau/datasets/dataset/carreaux/8_carreaux.png',\n",
    "        '9_carreaux': '/Users/valentindaveau/reseau/datasets/dataset/carreaux/9_carreaux.png',\n",
    "        '10_carreaux': '/Users/valentindaveau/reseau/datasets/dataset/carreaux/10_carreaux.png',\n",
    "        '11_carreaux': '/Users/valentindaveau/reseau/datasets/dataset/carreaux/11_carreaux.png',\n",
    "        '12_carreaux': '/Users/valentindaveau/reseau/datasets/dataset/carreaux/12_carreaux.png',\n",
    "        '13_carreaux': '/Users/valentindaveau/reseau/datasets/dataset/carreaux/13_carreaux.png',\n",
    "        '1_coeur': '/Users/valentindaveau/reseau/datasets/dataset/coeur/1_coeur.png',\n",
    "        '2_coeur': '/Users/valentindaveau/reseau/datasets/dataset/coeur/2_coeur.png',\n",
    "        '3_coeur': '/Users/valentindaveau/reseau/datasets/dataset/coeur/3_coeur.png',\n",
    "        '4_coeur': '/Users/valentindaveau/reseau/datasets/dataset/coeur/4_coeur.png',\n",
    "        '5_coeur': '/Users/valentindaveau/reseau/datasets/dataset/coeur/5_coeur.png',\n",
    "        '6_coeur': '/Users/valentindaveau/reseau/datasets/dataset/coeur/6_coeur.png',\n",
    "        '7_coeur': '/Users/valentindaveau/reseau/datasets/dataset/coeur/7_coeur.png',\n",
    "        '8_coeur': '/Users/valentindaveau/reseau/datasets/dataset/coeur/8_coeur.png',\n",
    "        '9_coeur': '/Users/valentindaveau/reseau/datasets/dataset/coeur/9_coeur.png',\n",
    "        '10_coeur': '/Users/valentindaveau/reseau/datasets/dataset/coeur/10_coeur.png',\n",
    "        '11_coeur': '/Users/valentindaveau/reseau/datasets/dataset/coeur/11_coeur.png',\n",
    "        '12_coeur': '/Users/valentindaveau/reseau/datasets/dataset/coeur/12_coeur.png',\n",
    "        '13_coeur': '/Users/valentindaveau/reseau/datasets/dataset/coeur/13_coeur.png',\n",
    "        '1_pique': '/Users/valentindaveau/reseau/datasets/dataset/pique/1_pique.png',\n",
    "        '2_pique': '/Users/valentindaveau/reseau/datasets/dataset/pique/2_pique.png',\n",
    "        '3_pique': '/Users/valentindaveau/reseau/datasets/dataset/pique/3_pique.png',\n",
    "        '4_pique': '/Users/valentindaveau/reseau/datasets/dataset/pique/4_pique.png',\n",
    "        '5_pique': '/Users/valentindaveau/reseau/datasets/dataset/pique/5_pique.png',\n",
    "        '6_pique': '/Users/valentindaveau/reseau/datasets/dataset/pique/6_pique.png',\n",
    "        '7_pique': '/Users/valentindaveau/reseau/datasets/dataset/pique/7_pique.png',\n",
    "        '8_pique': '/Users/valentindaveau/reseau/datasets/dataset/pique/8_pique.png',\n",
    "        '9_pique': '/Users/valentindaveau/reseau/datasets/dataset/pique/9_pique.png',\n",
    "        '10_pique': '/Users/valentindaveau/reseau/datasets/dataset/pique/10_pique.png',\n",
    "        '11_pique': '/Users/valentindaveau/reseau/datasets/dataset/pique/11_pique.png',\n",
    "        '12_pique': '/Users/valentindaveau/reseau/datasets/dataset/pique/12_pique.png',\n",
    "        '13_pique': '/Users/valentindaveau/reseau/datasets/dataset/pique/13_pique.png',\n",
    "        '1_trefle': '/Users/valentindaveau/reseau/datasets/dataset/trefle/1_trefle.png',\n",
    "        '2_trefle': '/Users/valentindaveau/reseau/datasets/dataset/trefle/2_trefle.png',\n",
    "        '3_trefle': '/Users/valentindaveau/reseau/datasets/dataset/trefle/3_trefle.png',\n",
    "        '4_trefle': '/Users/valentindaveau/reseau/datasets/dataset/trefle/4_trefle.png',\n",
    "        '5_trefle': '/Users/valentindaveau/reseau/datasets/dataset/trefle/5_trefle.png',\n",
    "        '6_trefle': '/Users/valentindaveau/reseau/datasets/dataset/trefle/6_trefle.png',\n",
    "        '7_trefle': '/Users/valentindaveau/reseau/datasets/dataset/trefle/7_trefle.png',\n",
    "        '8_trefle': '/Users/valentindaveau/reseau/datasets/dataset/trefle/8_trefle.png',\n",
    "        '9_trefle': '/Users/valentindaveau/reseau/datasets/dataset/trefle/9_trefle.png',\n",
    "        '10_trefle': '/Users/valentindaveau/reseau/datasets/dataset/trefle/10_trefle.png',\n",
    "        '11_trefle': '/Users/valentindaveau/reseau/datasets/dataset/trefle/11_trefle.png',\n",
    "        '12_trefle': '/Users/valentindaveau/reseau/datasets/dataset/trefle/12_trefle.png',\n",
    "        '13_trefle': '/Users/valentindaveau/reseau/datasets/dataset/trefle/13_trefle.png',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10ecb55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "        layers.InputLayer(input_shape=input_shape),\n",
    "        layers.Rescaling(1./255),\n",
    "        layers.Conv2D(128, 4, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 4, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, 4, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(16, 4, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax',dtype='float32')   #utilise un système de probabilités : probabilité que l'image appartienne à chaque classe\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a27d0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',     #Descente de gradient stochastique\n",
    "                  loss=losses.SparseCategoricalCrossentropy(from_logits=False),  #Essayer True\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b9a4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, class_names, img_path, img_height, img_width):\n",
    "    image_to_predict = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    img_to_predict = np.expand_dims(cv2.resize(image_to_predict, (img_height, img_width)), axis=0)\n",
    "    prediction = model.predict(img_to_predict)\n",
    "    res = np.argmax(prediction, axis=1)[0]    #argmax renvoie la valeur max des probabilités calculées ie renvoie la classe la plus probable\n",
    "    return class_names[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9be7fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDisplay(QWidget):\n",
    "    def __init__(self, img_a_predire, predictions):\n",
    "        super().__init__()\n",
    "        self.img_a_predire = img_a_predire\n",
    "        self.predictions = predictions\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        # Layout principal en QGridLayout\n",
    "        grid = QGridLayout()\n",
    "\n",
    "        for idx, (img_path, prediction) in enumerate(zip(self.img_a_predire, self.predictions)):\n",
    "            # Labels pour les images\n",
    "            label_predicted = QLabel(self)\n",
    "            label_predicted.setPixmap(QPixmap(img_path).scaled(200, 300, Qt.AspectRatioMode.KeepAspectRatio))\n",
    "            label_predicted.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "\n",
    "            label_to_predict = QLabel(self)\n",
    "            label_to_predict.setPixmap(QPixmap(card_dir[prediction]).scaled(200, 300, Qt.AspectRatioMode.KeepAspectRatio))\n",
    "            label_to_predict.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "\n",
    "            # Captions\n",
    "            caption_predicted = QLabel('Carte à prédire', self)\n",
    "            caption_predicted.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "\n",
    "            caption_to_predict = QLabel('Prédiction', self)\n",
    "            caption_to_predict.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "\n",
    "            # Placement dans la grille (2 colonnes et 2 lignes)\n",
    "            row = idx % 2\n",
    "            col = idx // 2\n",
    "\n",
    "            grid.addWidget(label_predicted, row * 2, col * 2)\n",
    "            grid.addWidget(caption_predicted, row * 2 + 1, col * 2)\n",
    "            grid.addWidget(label_to_predict, row * 2, col * 2 + 1)\n",
    "            grid.addWidget(caption_to_predict, row * 2 + 1, col * 2 + 1)\n",
    "\n",
    "        self.setLayout(grid)\n",
    "        self.setGeometry(100, 100, 800, 600)\n",
    "        self.setWindowTitle('Image Prediction Display')\n",
    "\n",
    "        # Set background color\n",
    "        self.setAutoFillBackground(True)\n",
    "        p = self.palette()\n",
    "        p.setColor(self.backgroundRole(), QColor('#096a09'))\n",
    "        self.setPalette(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b99d039a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs détectés: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs détectés:\", gpus)\n",
    "if not gpus:\n",
    "    raise RuntimeError(\"Aucun GPU détecté. Vérifie l'installation de tensorflow-metal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be0661d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "370/505 [====================>.........] - ETA: 27s - loss: 3.9349 - accuracy: 0.0396"
     ]
    }
   ],
   "source": [
    "start_reseau = time.time()\n",
    "start_pred = time.time()\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"logs\", histogram_freq=1, write_images=True)\n",
    "    \n",
    "model.fit(\n",
    "        train_data,\n",
    "        validation_data=val_data,\n",
    "        epochs=epochs,\n",
    "        callbacks=[tensorboard_callback])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "end_reseau = time.time()\n",
    "\n",
    "t_reseau_s = end_reseau - start_reseau\n",
    "t_reseau_h = t_reseau_s / 3600\n",
    "print(\"Temps d'entrainement :\", t_reseau_h, \" heures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "075fa56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps de prédiction : 4.0001339382595486e-08  heures\n"
     ]
    }
   ],
   "source": [
    "start_pred=time.time()\n",
    "\n",
    "img_a_predire = [\n",
    "    '/Users/valentindaveau/reseau/prediction/Conversion 50 percent.png',\n",
    "    '/Users/valentindaveau/reseau/prediction/Convertio IMG 5519.png',\n",
    "    '/Users/valentindaveau/reseau/prediction/IMG 5521.png',\n",
    "    '/Users/valentindaveau/reseau/prediction/IMG 5522.png'\n",
    "]\n",
    "\n",
    "def main():\n",
    "    predictions = [predict_image(model, class_names, img, img_height, img_width) for img in img_a_predire]\n",
    "\n",
    "    app = QApplication(sys.argv)\n",
    "    ex = ImageDisplay(img_a_predire, predictions)\n",
    "    ex.show()\n",
    "    sys.exit(app.exec_())\n",
    "\n",
    "\n",
    "end_pred=time.time()\n",
    "t_pred_s = end_pred - start_pred\n",
    "t_pred_h = t_pred_s / 3600\n",
    "print(\"Temps de prédiction :\", t_pred_h, \" heures\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfmetal310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
