{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers, preprocessing, callbacks, losses, utils, models\n",
    "import sys\n",
    "import PyQt5\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QWidget, QVBoxLayout, QHBoxLayout, QGridLayout,QFrame\n",
    "from PyQt5.QtGui import QPixmap, QPainter, QPen, QColor\n",
    "from PyQt5.QtCore import Qt\n",
    "import time\n",
    "import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79400eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©tection automatique du GPU Apple (Metal)\n",
    "devices = tf.config.list_physical_devices()\n",
    "gpu_devices = [d for d in devices if d.device_type == \"GPU\"]\n",
    "if gpu_devices:\n",
    "    print(\"‚úÖ GPU Apple d√©tect√© :\", gpu_devices)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucun GPU Apple d√©tect√©, utilisation du CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e6f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Parsing des fichiers\n",
    "# =========================\n",
    "\n",
    "def load_sequence_txt(path):\n",
    "    \"\"\"\n",
    "    Lit un .txt o√π chaque ligne est une frame : \"v1;v2;...;vN;\"\n",
    "    -> retourne un numpy array (T, D) o√π T = nb de frames, D = nb de features par frame\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = [p for p in line.strip().split(\";\") if p.strip() != \"\"]\n",
    "            if not parts:\n",
    "                continue\n",
    "            vec = list(map(float, parts))\n",
    "            feats.append(vec)\n",
    "    X = np.array(feats, dtype=np.float32)  # (T, D)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2) Pr√©traitements\n",
    "# =========================\n",
    "\n",
    "def normalize_framewise(X):\n",
    "    \"\"\"\n",
    "    Normalisation simple frame-par-frame :\n",
    "    - centrage par la moyenne\n",
    "    - mise √† l‚Äô√©chelle par l‚Äô√©cart-type\n",
    "    Remarque : si tes features sont des coordonn√©es articulaires (x,y,z) concat√©n√©es,\n",
    "    tu peux remplacer par un centrage/scale g√©om√©trique (soustraire le 'poignet', etc.).\n",
    "    \"\"\"\n",
    "    Xn = X.copy()\n",
    "    mu = Xn.mean(axis=0, keepdims=True)      # (1, D)\n",
    "    sigma = Xn.std(axis=0, keepdims=True) + 1e-8\n",
    "    Xn = (Xn - mu) / sigma\n",
    "    return Xn\n",
    "\n",
    "def load_dataset_from_folder(seq_folder, max_len=200):\n",
    "    \"\"\"\n",
    "    Charge toutes les s√©quences *.txt du dossier.\n",
    "    Chaque fichier correspond √† un seul geste, dont le label est le nom du fichier (sans extension).\n",
    "    Normalise chaque s√©quence.\n",
    "    Pad/tronque √† max_len.\n",
    "    Retourne X (N, max_len, D), y (N,), class_names\n",
    "    \"\"\"\n",
    "    sequences = sorted(glob.glob(os.path.join(seq_folder, \"*.txt\")))\n",
    "    X_list, y_list = [], []\n",
    "    label_to_id = {}\n",
    "    next_id = 0\n",
    "\n",
    "    for path in sequences:\n",
    "        label = os.path.splitext(os.path.basename(path))[0]\n",
    "        X = load_sequence_txt(path)\n",
    "        X = normalize_framewise(X)\n",
    "\n",
    "        # padding/tronquage √† max_len\n",
    "        if len(X) >= max_len:\n",
    "            seg = X[:max_len]\n",
    "        else:\n",
    "            pad = np.zeros((max_len - len(X), X.shape[1]), dtype=X.dtype)\n",
    "            seg = np.vstack([X, pad])\n",
    "\n",
    "        if label not in label_to_id:\n",
    "            label_to_id[label] = next_id\n",
    "            next_id += 1\n",
    "        y = label_to_id[label]\n",
    "        X_list.append(seg)\n",
    "        y_list.append(y)\n",
    "\n",
    "    if not X_list:\n",
    "        raise RuntimeError(\"Aucun segment construit (v√©rifie les chemins et les fichiers).\")\n",
    "\n",
    "    X = np.stack(X_list, axis=0)          # (N, max_len, D)\n",
    "    y = np.array(y_list, dtype=np.int64)  # (N,)\n",
    "    id_to_label = {v:k for k,v in label_to_id.items()}\n",
    "    class_names = [id_to_label[i] for i in range(len(id_to_label))]\n",
    "    return X, y, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b6e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 4) Mod√®le (BiLSTM)\n",
    "# =========================\n",
    "\n",
    "def make_model(T, D, C):\n",
    "    \"\"\"\n",
    "    T = longueur max (max_len)\n",
    "    D = nb features par frame\n",
    "    C = nb de classes\n",
    "    \"\"\"\n",
    "    inp = layers.Input(shape=(T, D))\n",
    "    x = layers.Masking(mask_value=0.0)(inp)\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(C, activation='softmax', dtype='float32')(x)\n",
    "    model = models.Model(inp, out)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aea3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5) Entra√Ænement + test\n",
    "# =========================\n",
    "\n",
    "# Dossier o√π se trouvent les fichiers *.txt\n",
    "seq_folder = \"/Users/valentindaveau/Documents/UE_Vision/Coordonnees\" \n",
    "\n",
    "# Construire le dataset\n",
    "X, y, class_names = load_dataset_from_folder(seq_folder, max_len=200)\n",
    "print(\"Dataset:\", X.shape, y.shape, class_names)\n",
    "\n",
    "# Split simple (train/val)\n",
    "idx = np.arange(len(X))\n",
    "np.random.shuffle(idx)\n",
    "split = int(0.8 * len(X))\n",
    "tr, va = idx[:split], idx[split:]\n",
    "Xtr, ytr = X[tr], y[tr]\n",
    "Xva, yva = X[va], y[va]\n",
    "\n",
    "T, D = X.shape[1], X.shape[2]\n",
    "C    = len(class_names)\n",
    "\n",
    "model_path = \"modele_gestes.keras\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"‚úÖ Mod√®le trouv√©, chargement du mod√®le sauvegard√©...\")\n",
    "    model = keras.models.load_model(model_path)\n",
    "    class_names = np.load(\"class_names.npy\", allow_pickle=True).tolist()\n",
    "    print(\"‚úÖ Noms de classes charg√©s :\", class_names)\n",
    "else:\n",
    "    print(\"‚öôÔ∏è  Aucun mod√®le trouv√©, entra√Ænement en cours...\")\n",
    "    model = make_model(T, D, C)\n",
    "    history = model.fit(Xtr, ytr, validation_data=(Xva, yva), epochs=20, batch_size=32)\n",
    "    model.save(model_path)\n",
    "    print(f\"üíæ Mod√®le sauvegard√© sous : {model_path}\")\n",
    "    np.save(\"class_names.npy\", class_names)\n",
    "    print(\"üíæ Noms de classes sauvegard√©s dans class_names.npy\")\n",
    "\n",
    "\n",
    "\n",
    "def normalize_landmarks(X20: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    X20: (20,3) ordre dataset.\n",
    "    - centre sur le poignet (point 0)\n",
    "    - mise √† l‚Äô√©chelle par une distance de r√©f√©rence stable (ex: WRIST‚ÜíMIDDLE_MCP)\n",
    "    \"\"\"\n",
    "    wrist = X20[0]\n",
    "    Xc = X20 - wrist\n",
    "    # distance de ref: WRIST (0) -> MIDDLE MCP (index MediaPipe 9, devenu X20[8] apr√®s mapping)\n",
    "    scale = np.linalg.norm(Xc[8]) + 1e-8\n",
    "    return Xc / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 8) Inf√©rence (sortie)\n",
    "# =========================\n",
    "\n",
    "def predict_sequence(model, path_txt, max_len=200):\n",
    "    X = load_sequence_txt(path_txt)\n",
    "    X = normalize_framewise(X)\n",
    "    # simple agr√©gation : on prend toute la s√©quence tronqu√©e/padd√©e\n",
    "    if len(X) >= max_len:\n",
    "        Xp = X[:max_len]\n",
    "    else:\n",
    "        pad = np.zeros((max_len - len(X), X.shape[1]), dtype=X.dtype)\n",
    "        Xp = np.vstack([X, pad])\n",
    "    Xp = np.expand_dims(Xp, axis=0)  # (1, T, D)\n",
    "    prob = model.predict(Xp, verbose=0)[0]  # (C,)\n",
    "    k = int(np.argmax(prob))\n",
    "    return k, float(prob[k])\n",
    "\n",
    "k, p = predict_sequence(model, \"1.txt\", max_len=200)\n",
    "print(f\"Pr√©diction pour 1.txt : {class_names[k]} (p={p:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfmetal310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
