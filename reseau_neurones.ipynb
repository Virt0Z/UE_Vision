{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fdf8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers, preprocessing, callbacks, losses, utils, models, regularizers\n",
    "import sys\n",
    "import PyQt5\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QWidget, QVBoxLayout, QHBoxLayout, QGridLayout,QFrame\n",
    "from PyQt5.QtGui import QPixmap, QPainter, QPen, QColor\n",
    "from PyQt5.QtCore import Qt\n",
    "import time\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79400eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GPU Apple d√©tect√© : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# D√©tection automatique du GPU Apple (Metal)\n",
    "devices = tf.config.list_physical_devices()\n",
    "gpu_devices = [d for d in devices if d.device_type == \"GPU\"]\n",
    "if gpu_devices:\n",
    "    print(\"‚úÖ GPU Apple d√©tect√© :\", gpu_devices)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucun GPU Apple d√©tect√©, utilisation du CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "561e6f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Parsing des fichiers\n",
    "# =========================\n",
    "\n",
    "def load_sequence_txt(path):\n",
    "    \"\"\"\n",
    "    Lit un .txt o√π chaque ligne est une frame : \"v1;v2;...;vN;\" ou \"v1 v2 ... vN\"\n",
    "    -> retourne un numpy array (T, D) o√π T = nb de frames, D = nb de features par frame\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            # D√©tection automatique du s√©parateur\n",
    "            if \";\" in line:\n",
    "                parts = [p for p in line.split(\";\") if p.strip() != \"\"]\n",
    "            else:\n",
    "                parts = [p for p in line.split() if p.strip() != \"\"]\n",
    "            try:\n",
    "                vec = list(map(float, parts))\n",
    "            except ValueError:\n",
    "                print(f\"‚ö†Ô∏è Ligne ignor√©e dans {path}: {line[:50]}...\")\n",
    "                continue\n",
    "            feats.append(vec)\n",
    "    X = np.array(feats, dtype=np.float32)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4970997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2) Pr√©traitements\n",
    "# =========================\n",
    "\n",
    "def normalize_framewise(X):\n",
    "    \"\"\"\n",
    "    Normalisation simple frame-par-frame :\n",
    "    - centrage par la moyenne\n",
    "    - mise √† l‚Äô√©chelle par l‚Äô√©cart-type\n",
    "    Remarque : si tes features sont des coordonn√©es articulaires (x,y,z) concat√©n√©es,\n",
    "    tu peux remplacer par un centrage/scale g√©om√©trique (soustraire le 'poignet', etc.).\n",
    "    \"\"\"\n",
    "    Xn = X.copy()\n",
    "    mu = Xn.mean(axis=0, keepdims=True)      # (1, D)\n",
    "    sigma = Xn.std(axis=0, keepdims=True) + 1e-8\n",
    "    Xn = (Xn - mu) / sigma\n",
    "    return Xn\n",
    "\n",
    "def load_dataset_from_folder(seq_folder):\n",
    "    \"\"\"\n",
    "    Charge tous les fichiers .txt du dossier.\n",
    "    Chaque fichier contient des lignes de coordonn√©es s√©par√©es par des espaces.\n",
    "    Chaque ligne est un exemple appartenant √† la classe correspondant au nom du fichier.\n",
    "    \"\"\"\n",
    "    sequences = sorted(glob.glob(os.path.join(seq_folder, \"*.txt\")))\n",
    "    X_list, y_list = [], []\n",
    "    label_to_id = {}\n",
    "    next_id = 0\n",
    "\n",
    "    for path in sequences:\n",
    "        label = os.path.splitext(os.path.basename(path))[0]\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                parts = [p for p in line.split() if p.strip() != \"\"]\n",
    "                try:\n",
    "                    vec = list(map(float, parts))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                X_list.append(vec)\n",
    "                if label not in label_to_id:\n",
    "                    label_to_id[label] = next_id\n",
    "                    next_id += 1\n",
    "                y_list.append(label_to_id[label])\n",
    "\n",
    "    X = np.array(X_list, dtype=np.float32)\n",
    "    y = np.array(y_list, dtype=np.int64)\n",
    "\n",
    "    id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "    class_names = [id_to_label[i] for i in range(len(id_to_label))]\n",
    "\n",
    "    print(f\"‚úÖ Dataset charg√© : {len(X)} exemples, {X.shape[1]} coordonn√©es, classes = {class_names}\")\n",
    "    return X, y, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55b6e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 4) Mod√®le (BatchNorm + Dropout + L2)\n",
    "# =========================\n",
    "\n",
    "def make_model(D, C):\n",
    "    reg = regularizers.l2(1e-4)\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(D,)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=reg),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=reg),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(C, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29aea3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset charg√© : 138728 exemples, 63 coordonn√©es, classes = ['call', 'dislike', 'fist', 'four', 'like']\n",
      "Dataset: (138728, 63) (138728,) ['call', 'dislike', 'fist', 'four', 'like']\n",
      "‚úÖ Normalisation globale appliqu√©e (moyenne et √©cart-type sauvegard√©s).\n",
      "‚öôÔ∏è  Aucun mod√®le trouv√©, entra√Ænement en cours...\n",
      "Epoch 1/20\n",
      "3902/3902 [==============================] - 56s 14ms/step - loss: 0.3190 - accuracy: 0.8872 - val_loss: 0.2233 - val_accuracy: 0.9173\n",
      "Epoch 2/20\n",
      "3902/3902 [==============================] - 51s 13ms/step - loss: 0.2558 - accuracy: 0.9063 - val_loss: 0.2163 - val_accuracy: 0.9191\n",
      "Epoch 3/20\n",
      "3902/3902 [==============================] - 52s 13ms/step - loss: 0.2439 - accuracy: 0.9094 - val_loss: 0.2132 - val_accuracy: 0.9198\n",
      "Epoch 4/20\n",
      "3902/3902 [==============================] - 52s 13ms/step - loss: 0.2362 - accuracy: 0.9122 - val_loss: 0.2067 - val_accuracy: 0.9211\n",
      "Epoch 5/20\n",
      "3902/3902 [==============================] - 52s 13ms/step - loss: 0.2309 - accuracy: 0.9126 - val_loss: 0.2070 - val_accuracy: 0.9203\n",
      "Epoch 6/20\n",
      "3902/3902 [==============================] - 51s 13ms/step - loss: 0.2267 - accuracy: 0.9135 - val_loss: 0.2066 - val_accuracy: 0.9213\n",
      "Epoch 7/20\n",
      "3902/3902 [==============================] - 51s 13ms/step - loss: 0.2246 - accuracy: 0.9136 - val_loss: 0.2016 - val_accuracy: 0.9229\n",
      "Epoch 8/20\n",
      "3902/3902 [==============================] - 51s 13ms/step - loss: 0.2217 - accuracy: 0.9146 - val_loss: 0.2018 - val_accuracy: 0.9210\n",
      "Epoch 9/20\n",
      "3902/3902 [==============================] - 51s 13ms/step - loss: 0.2172 - accuracy: 0.9151 - val_loss: 0.1992 - val_accuracy: 0.9214\n",
      "Epoch 10/20\n",
      "3902/3902 [==============================] - 49s 12ms/step - loss: 0.2176 - accuracy: 0.9155 - val_loss: 0.1969 - val_accuracy: 0.9222\n",
      "Epoch 11/20\n",
      "3902/3902 [==============================] - 51s 13ms/step - loss: 0.2176 - accuracy: 0.9151 - val_loss: 0.1995 - val_accuracy: 0.9209\n",
      "Epoch 12/20\n",
      "3902/3902 [==============================] - 52s 13ms/step - loss: 0.2156 - accuracy: 0.9157 - val_loss: 0.1984 - val_accuracy: 0.9227\n",
      "Epoch 13/20\n",
      "3902/3902 [==============================] - 50s 13ms/step - loss: 0.2144 - accuracy: 0.9158 - val_loss: 0.1960 - val_accuracy: 0.9216\n",
      "Epoch 14/20\n",
      "3902/3902 [==============================] - 52s 13ms/step - loss: 0.2120 - accuracy: 0.9170 - val_loss: 0.1934 - val_accuracy: 0.9218\n",
      "Epoch 15/20\n",
      "3902/3902 [==============================] - 53s 14ms/step - loss: 0.2128 - accuracy: 0.9159 - val_loss: 0.1931 - val_accuracy: 0.9217\n",
      "Epoch 16/20\n",
      "3902/3902 [==============================] - 53s 14ms/step - loss: 0.2107 - accuracy: 0.9164 - val_loss: 0.1953 - val_accuracy: 0.9215\n",
      "Epoch 17/20\n",
      "3902/3902 [==============================] - 52s 13ms/step - loss: 0.2106 - accuracy: 0.9165 - val_loss: 0.1929 - val_accuracy: 0.9219\n",
      "Epoch 18/20\n",
      "3902/3902 [==============================] - 52s 13ms/step - loss: 0.2097 - accuracy: 0.9171 - val_loss: 0.1980 - val_accuracy: 0.9221\n",
      "Epoch 19/20\n",
      "3902/3902 [==============================] - 51s 13ms/step - loss: 0.2090 - accuracy: 0.9163 - val_loss: 0.1906 - val_accuracy: 0.9230\n",
      "Epoch 20/20\n",
      "3902/3902 [==============================] - 51s 13ms/step - loss: 0.2079 - accuracy: 0.9174 - val_loss: 0.1900 - val_accuracy: 0.9229\n",
      "‚è∞ Temps d'entra√Ænement : 1033.55 secondes (17.23 min)\n",
      "üíæ Mod√®le sauvegard√© sous : modele_gestes_20x32_90%.keras\n",
      "üíæ Noms de classes sauvegard√©s dans class_names.npy\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 5) Entra√Ænement + test\n",
    "# =========================\n",
    "\n",
    "# Dossier o√π se trouvent les fichiers *.txt\n",
    "seq_folder = \"/Users/valentindaveau/Documents/UE_Vision/Coords\" \n",
    "\n",
    "# Construire le dataset\n",
    "X, y, class_names = load_dataset_from_folder(seq_folder)\n",
    "print(\"Dataset:\", X.shape, y.shape, class_names)\n",
    "\n",
    "train_val=0.9\n",
    "\n",
    "# Split simple (train/val)\n",
    "idx = np.arange(len(X))\n",
    "np.random.shuffle(idx)\n",
    "split = int(train_val * len(X))\n",
    "tr, va = idx[:split], idx[split:]\n",
    "Xtr, ytr = X[tr], y[tr]\n",
    "Xva, yva = X[va], y[va]\n",
    "\n",
    "# Normalisation globale bas√©e sur le train\n",
    "mu = Xtr.mean(axis=0, keepdims=True)\n",
    "sigma = Xtr.std(axis=0, keepdims=True) + 1e-8\n",
    "Xtr = (Xtr - mu) / sigma\n",
    "Xva = (Xva - mu) / sigma\n",
    "np.save(\"norm_mu.npy\", mu)\n",
    "np.save(\"norm_sigma.npy\", sigma)\n",
    "print(\"‚úÖ Normalisation globale appliqu√©e (moyenne et √©cart-type sauvegard√©s).\")\n",
    "\n",
    "D = X.shape[1]\n",
    "C = len(class_names)\n",
    "\n",
    "model_path = \"modele_gestes_20x32_90%.keras\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"‚úÖ Mod√®le trouv√©, chargement du mod√®le sauvegard√©...\")\n",
    "    model = keras.models.load_model(model_path)\n",
    "    class_names = np.load(\"class_names.npy\", allow_pickle=True).tolist()\n",
    "    print(\"‚úÖ Noms de classes charg√©s :\", class_names)\n",
    "else:\n",
    "    print(\"‚öôÔ∏è  Aucun mod√®le trouv√©, entra√Ænement en cours...\")\n",
    "    model = make_model(D,C)\n",
    "    start_time = time.time()\n",
    "    history = model.fit(Xtr, ytr, validation_data=(Xva, yva), epochs=20, batch_size=32)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"‚è∞ Temps d'entra√Ænement : {training_time:.2f} secondes ({training_time/60:.2f} min)\")\n",
    "    model.save(model_path)\n",
    "    print(f\"üíæ Mod√®le sauvegard√© sous : {model_path}\")\n",
    "    np.save(\"class_names.npy\", class_names)\n",
    "    print(\"üíæ Noms de classes sauvegard√©s dans class_names.npy\")\n",
    "\n",
    "\n",
    "\n",
    "def normalize_landmarks(X20: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    X20: (20,3) ordre dataset.\n",
    "    - centre sur le poignet (point 0)\n",
    "    - mise √† l‚Äô√©chelle par une distance de r√©f√©rence stable (ex: WRIST‚ÜíMIDDLE_MCP)\n",
    "    \"\"\"\n",
    "    wrist = X20[0]\n",
    "    Xc = X20 - wrist\n",
    "    # distance de ref: WRIST (0) -> MIDDLE MCP (index MediaPipe 9, devenu X20[8] apr√®s mapping)\n",
    "    scale = np.linalg.norm(Xc[8]) + 1e-8\n",
    "    return Xc / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b26c617d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39margmax(prob))\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m k, \u001b[38;5;28mfloat\u001b[39m(prob[k])\n\u001b[0;32m---> 19\u001b[0m k, p \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPr√©diction pour 1.txt : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names[k]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (p=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m, in \u001b[0;36mpredict_sequence\u001b[0;34m(model, path_txt, max_len)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_sequence\u001b[39m(model, path_txt, max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mload_sequence_txt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_txt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     X \u001b[38;5;241m=\u001b[39m normalize_framewise(X)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# simple agr√©gation : on prend toute la s√©quence tronqu√©e/padd√©e\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m, in \u001b[0;36mload_sequence_txt\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mLit un .txt o√π chaque ligne est une frame : \"v1;v2;...;vN;\" ou \"v1 v2 ... vN\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m-> retourne un numpy array (T, D) o√π T = nb de frames, D = nb de features par frame\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m feats \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m     13\u001b[0m         line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tfmetal310/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1.txt'"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 8) Inf√©rence (sortie)\n",
    "# =========================\n",
    "\n",
    "def predict_sequence(model, path_txt, max_len=200):\n",
    "    X = load_sequence_txt(path_txt)\n",
    "    X = normalize_framewise(X)\n",
    "    # simple agr√©gation : on prend toute la s√©quence tronqu√©e/padd√©e\n",
    "    if len(X) >= max_len:\n",
    "        Xp = X[:max_len]\n",
    "    else:\n",
    "        pad = np.zeros((max_len - len(X), X.shape[1]), dtype=X.dtype)\n",
    "        Xp = np.vstack([X, pad])\n",
    "    Xp = np.expand_dims(Xp, axis=0)  # (1, T, D)\n",
    "    prob = model.predict(Xp, verbose=0)[0]  # (C,)\n",
    "    k = int(np.argmax(prob))\n",
    "    return k, float(prob[k])\n",
    "\n",
    "k, p = predict_sequence(model, \"1.txt\", max_len=200)\n",
    "print(f\"Pr√©diction pour 1.txt : {class_names[k]} (p={p:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd473857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Classes connues par le mod√®le : ['call', 'dislike', 'fist', 'four', 'like']\n",
      "Nombre total de classes : 5\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"modele_gestes_40x32.keras\")\n",
    "model.summary()\n",
    "class_names = np.load(\"class_names.npy\", allow_pickle=True).tolist()\n",
    "mu = np.load(\"norm_mu.npy\")\n",
    "sigma = np.load(\"norm_sigma.npy\")\n",
    "\n",
    "class_names = np.load(\"class_names.npy\", allow_pickle=True).tolist()\n",
    "print(\"üß† Classes connues par le mod√®le :\", class_names)\n",
    "print(\"Nombre total de classes :\", len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b40385b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762792376.253183 10452505 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M2\n",
      "W0000 00:00:1762792376.389879 10475008 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762792376.406482 10475012 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé• Cam√©ra ouverte √† l'index 0\n",
      "üé• Cam√©ra pr√™te. Appuie sur ESC pour quitter.\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# Ouverture cam√©ra\n",
    "cap = None\n",
    "for i in [0, 1]:\n",
    "    cap = cv2.VideoCapture(i, cv2.CAP_AVFOUNDATION)\n",
    "    if cap.isOpened():\n",
    "        print(f\"üé• Cam√©ra ouverte √† l'index {i}\")\n",
    "        break\n",
    "if cap is None or not cap.isOpened():\n",
    "    raise RuntimeError(\"‚ùå Aucune cam√©ra utilisable d√©tect√©e.\")\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "time.sleep(1.0)\n",
    "\n",
    "cv2.namedWindow(\"Reconnaissance de gestes\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"Reconnaissance de gestes\", 900, 700)\n",
    "\n",
    "last_pred_time = 0\n",
    "pred_interval = 0.3\n",
    "last_preds = None\n",
    "last_top3_idx = None\n",
    "\n",
    "print(\"üé• Cam√©ra pr√™te. Appuie sur ESC pour quitter.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"‚ö†Ô∏è cap.read() a √©chou√©.\")\n",
    "        break\n",
    "\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    out = frame.copy()\n",
    "    now = time.time()\n",
    "\n",
    "    # --- D√©tection et pr√©diction ---\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(out, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            coords = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark], dtype=np.float32).flatten()\n",
    "            coords = (coords - mu.flatten()) / sigma.flatten()\n",
    "\n",
    "            # Nouvelle pr√©diction une fois par seconde\n",
    "            if now - last_pred_time > pred_interval:\n",
    "                preds = model.predict(np.expand_dims(coords, axis=0), verbose=0)[0]\n",
    "                top3_idx = preds.argsort()[-3:][::-1]\n",
    "                last_preds = preds\n",
    "                last_top3_idx = top3_idx\n",
    "                last_pred_time = now\n",
    "\n",
    "    # --- Affichage du dernier r√©sultat connu (√† chaque frame) ---\n",
    "    if last_preds is not None and last_top3_idx is not None:\n",
    "        for i, idx in enumerate(last_top3_idx):\n",
    "            text = f\"{class_names[idx]} : {last_preds[idx]*100:.1f}%\"\n",
    "            y_pos = 40 + i * 35\n",
    "            color = (0, 255, 0) if i == 0 else (255, 255, 255)\n",
    "            cv2.putText(out, text, (20, y_pos),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2, cv2.LINE_AA)\n",
    "\n",
    "    # --- Affichage cam√©ra ---\n",
    "    cv2.imshow(\"Reconnaissance de gestes\", out)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfmetal310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
